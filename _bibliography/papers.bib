---
---

@inproceedings{bang-etal-2023-multitask,
    title = "A Multitask, Multilingual, Multimodal Evaluation of {C}hat{GPT} on Reasoning, Hallucination, and Interactivity",
    author = "Bang, Yejin  and
      Cahyawijaya, Samuel  and
      Lee, Nayeon  and
      Dai, Wenliang  and
      Su, Dan  and
      Wilie, Bryan  and
      Lovenia, Holy  and
      Ji, Ziwei  and
      Yu, Tiezheng  and
      Chung, Willy  and
      Do, Quyet V.  and
      Xu, Yan  and
      Fung, Pascale",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.ijcnlp-main.45",
    pages = "675--718",
}

@inproceedings{cahyawijaya2023nusacrowd,
  title={NusaCrowd: Open source initiative for Indonesian NLP resources},
  author={Cahyawijaya, Samuel and Lovenia, Holy and Aji, Alham Fikri and Winata, Genta and Wilie, Bryan and Koto, Fajri and Mahendra, Rahmad and Wibisono, Christian and Romadhony, Ade and Vincentio, Karissa and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13745--13818},
  year={2023}
}

@inproceedings{wilie2020indonlu,
  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},
  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},
  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},
  pages={843--857},
  year={2020}
}

@inproceedings{ishii2023contrastive,
  title={Contrastive Learning for Inference in Dialogue},
  author={Ishii, Etsuko and Xu, Yan and Wilie, Bryan and Ji, Ziwei and Lovenia, Holy and Chung, Willy and Fung, Pascale},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={10202--10221},
  year={2023}
}

@inproceedings{chung-etal-2023-instructtods,
    title = "{I}nstruct{TODS}: Large Language Models for End-to-End Task-Oriented Dialogue Systems",
    author = "Chung, Willy  and
      Cahyawijaya, Samuel  and
      Wilie, Bryan  and
      Lovenia, Holy  and
      Fung, Pascale",
    editor = "Chen, Kehai  and
      Ku, Lun-Wei",
    booktitle = "Proceedings of the Second Workshop on Natural Language Interfaces",
    month = nov,
    year = "2023",
    address = "Bali, Indonesia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nlint-1.1",
    pages = "1--21",
}

@inproceedings{wilie2023pick,
  title={PICK: Polished \& Informed Candidate Scoring for Knowledge-Grounded Dialogue Systems},
  author={Wilie, Bryan and Xu, Yan and Chung, Willy and Cahyawijaya, Samuel and Lovenia, Holy and Fung, Pascale},
  booktitle={Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={980--995},
  year={2023},
  selected={true}
}


@inproceedings{cahyawijaya-etal-2023-nusawrites,
    title = "{N}usa{W}rites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages",
    author = "Cahyawijaya, Samuel  and
      Lovenia, Holy  and
      Koto, Fajri  and
      Adhista, Dea  and
      Dave, Emmanuel  and
      Oktavianti, Sarah  and
      Akbar, Salsabil  and
      Lee, Jhonson  and
      Shadieq, Nuur  and
      Cenggoro, Tjeng Wawan  and
      Linuwih, Hanung  and
      Wilie, Bryan  and
      Muridan, Galih  and
      Winata, Genta  and
      Moeljadi, David  and
      Aji, Alham Fikri  and
      Purwarianti, Ayu  and
      Fung, Pascale",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.ijcnlp-main.60",
    pages = "921--945",
}


@inproceedings{ji-etal-2023-rho,
    title = "{RHO}: Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding",
    author = "Ji, Ziwei  and
      Liu, Zihan  and
      Lee, Nayeon  and
      Yu, Tiezheng  and
      Wilie, Bryan  and
      Zeng, Min  and
      Fung, Pascale",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.275",
    doi = "10.18653/v1/2023.findings-acl.275",
    pages = "4504--4522",
    abstract = "Dialogue systems can leverage large pre-trained language models and knowledge to generate fluent and informative responses. However, these models are still prone to produce hallucinated responses not supported by the input source, which greatly hinders their application. The heterogeneity between external knowledge and dialogue context challenges representation learning and source integration, which further contributes to unfaithfulness. To handle this challenge and generate more faithful responses, this paper presents RHO (œÅ) utilizing the representations of linked entities and relation predicates from a knowledge graph (KG). We propose (1) local knowledge grounding to combine textual embeddings with the corresponding KG embeddings; and (2) global knowledge grounding to equip RHO with multi-hop reasoning abilities via the attention mechanism. In addition, we devise a response re-ranking technique based on walks over KG sub-graphs for better conversational reasoning. Experimental results on OpenDialKG (Moon et al., 2019) show that our approach significantly outperforms state-of-the-art methods on both automatic and human evaluation by a large margin, especially in hallucination reduction (17.54{\%} in FeQA (Durmus et al., 2020)).",
}

@inproceedings{cahyawijaya2022long,
  title={How Long Is Enough? Exploring the Optimal Intervals of Long-Range Clinical Note Language Modeling},
  author={Cahyawijaya, Samuel and Wilie, Bryan and Lovenia, Holy and Zhong, Huan and Zhong, MingQian and Ip, Yuk Yu Nancy and Fung, Pascale},
  booktitle={Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)},
  pages={160--172},
  year={2022}
}

@inproceedings{lovenia2022every,
  title={Every picture tells a story: Image-grounded controllable stylistic story generation},
  author={Lovenia, Holy and Wilie, Bryan and Barraud, Romain and Cahyawijaya, Samuel and Chung, Willy and Fung, Pascale},
  booktitle={Proceedings of the 6th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
  pages={40--52},
  year={2022}
}


@inproceedings{gehrmann2022gemv2,
  title={GEMv2: Multilingual NLG Benchmarking in a Single Line of Code},
  author={Gehrmann, Sebastian and Bhattacharjee, Abhik and Mahendiran, Abinaya and Wang, Alex and Papangelis, Alexandros and Madaan, Aman and Mcmillan-major, Angelina and Shvets, Anna and Upadhyay, Ashish and Bohnet, Bernd},
  booktitle={Proceedings of the The 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={266--281},
  year={2022}
}

@inproceedings{ishii2022integrating,
  title={Integrating Question Rewrites in Conversational Question Answering: A Reinforcement Learning Approach},
  author={Ishii, Etsuko and Wilie, Bryan and Xu, Yan and Cahyawijaya, Samuel and Fung, Pascale},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop},
  pages={55--66},
  year={2022}
}

@inproceedings{ishii2022can,
  title={Can Question Rewriting Help Conversational Question Answering?},
  author={Ishii, Etsuko and Xu, Yan and Cahyawijaya, Samuel and Wilie, Bryan},
  booktitle={Proceedings of the Third Workshop on Insights from Negative Results in NLP},
  pages={94--99},
  year={2022}
}


@inproceedings{lovenia-etal-2022-clozer,
    title = "Clozer{''}:{''} Adaptable Data Augmentation for Cloze-style Reading Comprehension",
    author = "Lovenia, Holy  and
      Wilie, Bryan  and
      Chung, Willy  and
      Min, Zeng  and
      Cahyawijaya, Samuel  and
      Su, Dan  and
      Fung, Pascale",
    editor = "Gella, Spandana  and
      He, He  and
      Majumder, Bodhisattwa Prasad  and
      Can, Burcu  and
      Giunchiglia, Eleonora  and
      Cahyawijaya, Samuel  and
      Min, Sewon  and
      Mozes, Maximilian  and
      Li, Xiang Lorraine  and
      Augenstein, Isabelle  and
      Rogers, Anna  and
      Cho, Kyunghyun  and
      Grefenstette, Edward  and
      Rimell, Laura  and
      Dyer, Chris",
    booktitle = "Proceedings of the 7th Workshop on Representation Learning for NLP",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.repl4nlp-1.7",
    doi = "10.18653/v1/2022.repl4nlp-1.7",
    pages = "60--66",
    abstract = "Task-adaptive pre-training (TAPT) alleviates the lack of labelled data and provides performance lift by adapting unlabelled data to downstream task. Unfortunately, existing adaptations mainly involve deterministic rules that cannot generalize well. Here, we propose Clozer, a sequence-tagging based cloze answer extraction method used in TAPT that is extendable for adaptation on any cloze-style machine reading comprehension (MRC) downstream tasks. We experiment on multiple-choice cloze-style MRC tasks, and show that Clozer performs significantly better compared to the oracle and state-of-the-art in escalating TAPT effectiveness in lifting model performance, and prove that Clozer is able to recognize the gold answers independently of any heuristics.",
}



@article{bang2022towards,
  title={Towards Answering Open-ended Ethical Quandary Questions},
  author={Bang, Yejin and Lee, Nayeon and Yu, Tiezheng and Khalatbari, Leila and Xu, Yan and Cahyawijaya, Samuel and Su, Dan and Wilie, Bryan and Barraud, Romain and Barezi, Elham J and others}
}

@article{dhole2023nl,
  title={NL-Augmenter: A Framework for Task-Sensitive Natural Language Augmentation},
  author={Dhole, Kaustubh and Gangal, Varun and Gehrmann, Sebastian and Gupta, Aadesh and Li, Zhenhao and Mahamood, Saad and Mahadiran, Abinaya and Mille, Simon and Shrivastava, Ashish and Tan, Samson and others},
  journal={Northern European Journal of Language Technology},
  volume={9},
  number={1},
  year={2023}
}

@article{cahyawijaya2021greenformer,
  title={Greenformer: Factorization toolkit for efficient deep neural networks},
  author={Cahyawijaya, Samuel and Winata, Genta Indra and Lovenia, Holy and Wilie, Bryan and Dai, Wenliang and Ishii, Etsuko and Fung, Pascale},
  journal={arXiv preprint arXiv:2109.06762},
  year={2021}
}